{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for ML"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/reinstate/MyData/code/mlops-finance/.venv/lib/python3.10/site-packages/great_expectations/compatibility/sqlalchemy.py:20: UserWarning: SQLAlchemy v2.0.0 or later is not yet supported by Great Expectations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "import json\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import importlib.util"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we've used unit and integration tests to test the functions that interact with our data but we haven't tested the validity of the data itself.\n",
    "\n",
    "We're going to use the great expectations library to test what our data is expected to look like. It's a library that allows us to create expectations as to what our data should look like in a standardized way. It also provides modules to seamlessly connect with backend data sources such as local file systems, S3, databases, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEETS_PATH = '../data/tweets.csv'\n",
    "TAGS_PATH = '../data/tags.txt'\n",
    "\n",
    "def get_idx_tag(path_file: str):\n",
    "    \"\"\"\n",
    "    Return a dictionnary composed of indices and tags\n",
    "\n",
    "    Args :\n",
    "        path_file (str) : location of file containing tags\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    dict_tags = dict()\n",
    "    with open(path_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if line != \"\\n\":\n",
    "                key_value = line.split(\":\")\n",
    "                key = int(key_value[0].split(\"_\")[-1][:-1])\n",
    "                value = line.split(\":\")[1].replace(\"\\n\", \"\")\n",
    "                dict_tags[key] = value.replace('\"', \"\")[1:]\n",
    "    return dict_tags\n",
    "\n",
    "\n",
    "def idx_to_tag(serie, dict_tags):\n",
    "    return serie.apply(lambda x: dict_tags[x])\n",
    "\n",
    "tweets = pd.read_csv(TWEETS_PATH)\n",
    "dict_tags = get_idx_tag(TAGS_PATH)\n",
    "\n",
    "labeled_tweets = tweets.copy()\n",
    "labeled_tweets.label = idx_to_tag(labeled_tweets.label, dict_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21107 tweets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: App...</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore bui...</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, cit...</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, bre...</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to...</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           label\n",
       "0  Here are Thursday's biggest analyst calls: App...  Analyst Update\n",
       "1  Buy Las Vegas Sands as travel to Singapore bui...  Analyst Update\n",
       "2  Piper Sandler downgrades DocuSign to sell, cit...  Analyst Update\n",
       "3  Analysts react to Tesla's latest earnings, bre...  Analyst Update\n",
       "4  Netflix and its peers are set for a ‘return to...  Analyst Update"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ge.dataset.PandasDataset(labeled_tweets)\n",
    "print (f\"{len(df)} tweets\")\n",
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to think about our entire dataset and all the features (columns) within it.\n",
    "\n",
    "Defaults expectations : \n",
    "\n",
    "- expect_table_columns_to_match_ordered_list : Presence of specific features\n",
    "- expect_compound_columns_to_be_unique : Unique combinations of features (detect data leaks!)\n",
    "- expect_column_values_to_not_be_null : Missing values\n",
    "- expect_column_values_to_be_of_type : Type adherence\n",
    "- expect_column_values_to_be_unique : Unique values\n",
    "- expect_column_values_to_be_in_set : List (categorical) / range (continuous) of allowed values\n",
    "- expect_column_pair_values_a_to_be_greater_than_b : Feature value relationships with other feature values\n",
    "- expect_table_row_count_to_be_between : Row count (exact or range) of samples\n",
    "- expect_column_mean_to_be_between : Value statistics (mean, std, median, max, min, sum, etc.)\n",
    "\n",
    "Custom expectations : [Here](https://docs.greatexpectations.io/docs/guides/expectations/creating_custom_expectations/overview/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": true,\n",
       "  \"meta\": {},\n",
       "  \"result\": {\n",
       "    \"element_count\": 21107,\n",
       "    \"unexpected_count\": 0,\n",
       "    \"unexpected_percent\": 0.0,\n",
       "    \"unexpected_percent_total\": 0.0,\n",
       "    \"partial_unexpected_list\": []\n",
       "  },\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemple 1 : Success\n",
    "\n",
    "# Missing values\n",
    "df.expect_column_values_to_not_be_null(column=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  \"success\": false,\n",
       "  \"meta\": {},\n",
       "  \"result\": {\n",
       "    \"element_count\": 21107,\n",
       "    \"missing_count\": 0,\n",
       "    \"missing_percent\": 0.0,\n",
       "    \"unexpected_count\": 21107,\n",
       "    \"unexpected_percent\": 100.0,\n",
       "    \"unexpected_percent_total\": 100.0,\n",
       "    \"unexpected_percent_nonmissing\": 100.0,\n",
       "    \"partial_unexpected_list\": [\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\",\n",
       "      \"Analyst Update\"\n",
       "    ]\n",
       "  },\n",
       "  \"exception_info\": {\n",
       "    \"raised_exception\": false,\n",
       "    \"exception_traceback\": null,\n",
       "    \"exception_message\": null\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exemple 2 : Failure\n",
    "\n",
    "# Type adherence\n",
    "df.expect_column_values_to_be_of_type(column=\"label\", type_=\"int\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to organizing expectations, it's recommended to start with table-level ones and then move on to individual feature columns.\n",
    "\n",
    "1. Table expectations : \n",
    "    - expect_table_columns_to_match_ordered_list\n",
    "    - expect_compound_columns_to_be_unique\n",
    "    - ...\n",
    "\n",
    "2. Column expectations :\n",
    "    - expect_column_values_to_be_unique\n",
    "    - expect_column_values_to_not_be_null\n",
    "    - ...\n",
    "\n",
    "We can group all the expectations together to create an Expectation Suite object which we can use to validate any Dataset module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"success\": false,\n",
      "  \"meta\": {\n",
      "    \"great_expectations_version\": \"0.16.8\",\n",
      "    \"expectation_suite_name\": \"default\",\n",
      "    \"run_id\": {\n",
      "      \"run_name\": null,\n",
      "      \"run_time\": \"2023-04-27T14:01:10.078198+02:00\"\n",
      "    },\n",
      "    \"batch_kwargs\": {\n",
      "      \"ge_batch_id\": \"328ba7e6-e4f3-11ed-b3ad-b0359fae9647\"\n",
      "    },\n",
      "    \"batch_markers\": {},\n",
      "    \"batch_parameters\": {},\n",
      "    \"validation_time\": \"20230427T120110.078055Z\",\n",
      "    \"expectation_suite_meta\": {\n",
      "      \"great_expectations_version\": \"0.16.8\"\n",
      "    }\n",
      "  },\n",
      "  \"evaluation_parameters\": {},\n",
      "  \"statistics\": {\n",
      "    \"evaluated_expectations\": 2,\n",
      "    \"successful_expectations\": 1,\n",
      "    \"unsuccessful_expectations\": 1,\n",
      "    \"success_percent\": 50.0\n",
      "  },\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"success\": false,\n",
      "      \"meta\": {},\n",
      "      \"result\": {\n",
      "        \"element_count\": 21107,\n",
      "        \"missing_count\": 0,\n",
      "        \"missing_percent\": 0.0,\n",
      "        \"unexpected_count\": 21107,\n",
      "        \"unexpected_percent\": 100.0,\n",
      "        \"unexpected_percent_total\": 100.0,\n",
      "        \"unexpected_percent_nonmissing\": 100.0,\n",
      "        \"partial_unexpected_list\": [\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\",\n",
      "          \"Analyst Update\"\n",
      "        ]\n",
      "      },\n",
      "      \"expectation_config\": {\n",
      "        \"kwargs\": {\n",
      "          \"column\": \"label\",\n",
      "          \"type_\": \"int\"\n",
      "        },\n",
      "        \"expectation_type\": \"expect_column_values_to_be_of_type\",\n",
      "        \"meta\": {}\n",
      "      },\n",
      "      \"exception_info\": {\n",
      "        \"raised_exception\": false,\n",
      "        \"exception_message\": null,\n",
      "        \"exception_traceback\": null\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Expectation suite\n",
    "expectation_suite = df.get_expectation_suite(discard_failed_expectations=False)\n",
    "print(df.validate(expectation_suite=expectation_suite, only_return_failures=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've worked with the Great Expectations library at the  notebook level but we can further organize our expectations by creating a Project.\n",
    "\n",
    "In the tests folder run the command ```great_expectations init```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
